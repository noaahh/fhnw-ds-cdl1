{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T18:54:58.859312Z",
     "start_time": "2024-06-01T18:54:57.494254Z"
    }
   },
   "cell_type": "code",
   "source": "import lightning as L\n",
   "id": "a96227b85a1b70b3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T18:54:58.865804Z",
     "start_time": "2024-06-01T18:54:58.860369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.utils.data import get_worker_info\n",
    "\n",
    "\n",
    "from typing import Dict, List, Tuple, TypeVar\n",
    "\n",
    "T = TypeVar('T')\n",
    "D = TypeVar('D')\n",
    "\n",
    "Hidden = List[Tuple[Tensor, ...]]\n",
    "\n",
    "def exists(var : T | None) -> bool:\n",
    "    return var is not None\n",
    "\n",
    "def default(var : T | None, val : D) -> T | D:\n",
    "    return var if exists(var) else val\n",
    "\n",
    "def enlarge_as(src : Tensor, other : Tensor) -> Tensor:\n",
    "    '''\n",
    "        Add sufficient number of singleton dimensions\n",
    "        to tensor a **to the right** so to match the\n",
    "        shape of tensor b. NOTE that simple broadcasting\n",
    "        works in the opposite direction.\n",
    "    '''\n",
    "    return rearrange(src, f'... -> ...{\" 1\" * (other.dim() - src.dim())}').contiguous()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CausalConv1d(nn.Conv1d):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride=1,\n",
    "            dilation=1,\n",
    "            groups=1,\n",
    "            bias=True\n",
    "    ):\n",
    "        self._padding = (kernel_size - 1) * dilation\n",
    "\n",
    "        super(CausalConv1d, self).__init__(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=self._padding,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=bias)\n",
    "\n",
    "    def forward(self, inp : Tensor) -> Tensor:\n",
    "        # Handle the case where input has only two dimensions\n",
    "        # we expect them to have semantics (batch, channels),\n",
    "        # so we add the missing dimension manually\n",
    "        if inp.dim() == 2: inp = rearrange(inp, 'b i -> b 1 i')\n",
    "\n",
    "        result = super(CausalConv1d, self).forward(inp)\n",
    "        if self._padding != 0: return result[..., :-self._padding]\n",
    "        return result\n",
    "\n",
    "class BlockLinear(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            block_dims : List[int | List[int]],\n",
    "            bias : bool = False,\n",
    "    ):\n",
    "        super(BlockLinear, self).__init__()\n",
    "\n",
    "        self._blocks = nn.ParameterList([\n",
    "            nn.Parameter(torch.randn(size, requires_grad=True))\n",
    "            for size in block_dims\n",
    "        ])\n",
    "\n",
    "        self._bias = nn.Parameter(torch.zeros(sum(block_dims))) if bias else None\n",
    "\n",
    "    def forward(self, inp : Tensor) -> Tensor:\n",
    "        # Assemble the blocks into a block-diagonal matrix\n",
    "        full = torch.block_diag(*self._blocks)\n",
    "\n",
    "        out = torch.matmul(full, inp)\n",
    "\n",
    "        if self._bias is not None:\n",
    "            out = out + self._bias\n",
    "\n",
    "        return out\n"
   ],
   "id": "20272b2239dd72bf",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T18:54:58.881305Z",
     "start_time": "2024-06-01T18:54:58.866502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from math import sqrt\n",
    "from torch import exp\n",
    "from torch import tanh\n",
    "from torch import sigmoid\n",
    "from einops import einsum, rearrange\n",
    "\n",
    "from torch import Tensor\n",
    "from typing import Tuple\n",
    "from torch.nn.functional import silu\n",
    "from torch.nn.functional import gelu\n",
    "\n",
    "class sLSTM(nn.Module):\n",
    "    '''The scalar-Long Short Term Memory (sLSTM) module as\n",
    "    originally introduced in Beck et al. (2024)] see:\n",
    "    (https://arxiv.org/abs/2405.04517).\n",
    "    \n",
    "    This model is a variant of the standard LSTM model and\n",
    "    offers two major improvements:\n",
    "    - Exponential gating with appropriate state normalization\n",
    "        to avoid overflows induced by the exponential function.\n",
    "    - A new memory mixing within heads but not across heads.\n",
    "    '''\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            inp_dim : int,\n",
    "            head_dim : int,\n",
    "            head_num : int,\n",
    "            ker_size : int = 4,\n",
    "            p_factor : float = 4/3,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.inp_dim = inp_dim\n",
    "        self.head_dim = head_dim\n",
    "        self.head_num = head_num\n",
    "\n",
    "        self.inp_norm = nn.LayerNorm(inp_dim)\n",
    "        self.hid_norm = nn.GroupNorm(head_num, head_dim * head_num)\n",
    "\n",
    "        self.causal_conv = CausalConv1d(1, 1, kernel_size=ker_size)\n",
    "\n",
    "        self.W_z = nn.Linear(inp_dim, head_num * head_dim)\n",
    "        self.W_i = nn.Linear(inp_dim, head_num * head_dim)\n",
    "        self.W_o = nn.Linear(inp_dim, head_num * head_dim)\n",
    "        self.W_f = nn.Linear(inp_dim, head_num * head_dim)\n",
    "\n",
    "        self.R_z = BlockLinear([(head_dim, head_dim)] * head_num)\n",
    "        self.R_i = BlockLinear([(head_dim, head_dim)] * head_num)\n",
    "        self.R_o = BlockLinear([(head_dim, head_dim)] * head_num)\n",
    "        self.R_f = BlockLinear([(head_dim, head_dim)] * head_num)\n",
    "\n",
    "        # NOTE: The factor of two in the output dimension of the up_proj\n",
    "        # is due to the fact that the output needs to branch into two\n",
    "        # separate outputs to account for the the gated GeLU connection.\n",
    "        # See Fig. 9 in the paper.\n",
    "        proj_dim = int(p_factor * head_num * head_dim)\n",
    "        self.up_proj   = nn.Linear(head_num * head_dim, 2 * proj_dim)\n",
    "        self.down_proj = nn.Linear(proj_dim, inp_dim)\n",
    "\n",
    "    def init_hidden(self) -> Tuple[Tensor, Tensor, Tensor, Tensor]:\n",
    "        '''Initialize the hidden state of the sLSTM model.\n",
    "\n",
    "        Args:\n",
    "            batch_size (int): The batch size of the input sequence.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Tensor, Tensor, Tensor, Tensor]: The hidden state tuple containing the cell state,\n",
    "                normalizer state, hidden state, and stabilizer state.\n",
    "        '''\n",
    "\n",
    "        n_0 = torch.ones (self.head_num * self.head_dim, device=self.device)\n",
    "        c_0 = torch.zeros(self.head_num * self.head_dim, device=self.device)\n",
    "        h_0 = torch.zeros(self.head_num * self.head_dim, device=self.device)\n",
    "        m_0 = torch.zeros(self.head_num * self.head_dim, device=self.device)\n",
    "\n",
    "        return c_0, n_0, h_0, m_0\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            seq: Tensor,\n",
    "            hid: Tuple[Tensor, Tensor, Tensor, Tensor],\n",
    "            use_conv : bool = False,\n",
    "    ) -> Tuple[Tensor, Tuple[Tensor, Tensor, Tensor, Tensor]]:\n",
    "        '''Forward pass of the sLSTM model.\n",
    "\n",
    "        Args:\n",
    "            seq (Tensor): The input sequence tensor of shape (batch_size, input_dim).\n",
    "            hid (Tuple[Tensor, Tensor, Tensor, Tensor]): The hidden state tuple containing the cell state,\n",
    "                normalizer state, hidden state, and stabilizer state.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Tensor, Tuple[Tensor, Tensor, Tensor, Tensor]]: The output tensor with the residual\n",
    "                connection and the newly updated hidden state tuple.\n",
    "        '''\n",
    "\n",
    "        b, d = seq.shape\n",
    "\n",
    "        # Separate the hidden (previous) state into the cell state,\n",
    "        # the normalizer state, the hidden state, and the stabilizer state.\n",
    "        c_tm1, n_tm1, h_tm1, m_tm1 = hid\n",
    "\n",
    "        x_t : Tensor = self.inp_norm(seq)\n",
    "\n",
    "        # Optional causal convolution block for the input\n",
    "        # and forget gates. See Fig. 9 in the paper.\n",
    "        if use_conv:\n",
    "            # FIXME: The causal conv branch is broken.\n",
    "            x_c = self.causal_conv(x_t)\n",
    "            x_c = silu(x_c).squeeze()\n",
    "        else:\n",
    "            x_c = x_t\n",
    "\n",
    "        # Project the input to the different heads for all\n",
    "        # the gates.\n",
    "        # NOTE: For input (i) and forget (f) inputs we use\n",
    "        # the output of the causal conv. See Fig. 9 in the paper.\n",
    "        i_t: Tensor = self.W_i(x_c) + self.R_i(h_tm1)\n",
    "        f_t: Tensor = self.W_f(x_c) + self.R_f(h_tm1)\n",
    "        z_t: Tensor = self.W_z(x_t) + self.R_z(h_tm1)\n",
    "        o_t: Tensor = self.W_o(x_t) + self.R_o(h_tm1)\n",
    "\n",
    "        # Compute the gated outputs for the newly computed inputs\n",
    "        m_t = torch.max(f_t + m_tm1, i_t)\n",
    "\n",
    "        i_t = exp(i_t - m_t)         # Eq. (16) in ref. paper | or Eq. (38) in supp. mat.\n",
    "        f_t = exp(f_t - m_t + m_tm1) # Eq. (17) in ref. paper | or Eq. (39) in supp. mat.\n",
    "\n",
    "        z_t = tanh(z_t)              # Eq. (11) in ref. paper\n",
    "        o_t = sigmoid(o_t)           # Eq. (14) in ref. paper\n",
    "\n",
    "        # Update the internal states of the model\n",
    "        c_t = f_t * c_tm1 + i_t * z_t # Eq. (8) in ref. paper\n",
    "        n_t = f_t * n_tm1 + i_t       # Eq. (9) in ref. paper\n",
    "        h_t = o_t * (c_t / n_t)       # Eq. (10) in ref. paper\n",
    "\n",
    "        # Compute the output of the LSTM block\n",
    "        out = self.hid_norm(h_t)\n",
    "\n",
    "        # Perform up-and-down projection of the output with\n",
    "        # projection factor 4/3. See Fig. (9) in supp. mat.\n",
    "        out1, out2 = self.up_proj(out).chunk(2, dim=-1)\n",
    "\n",
    "        out = out1 + gelu(out2)\n",
    "        out = self.down_proj(out)\n",
    "\n",
    "        # Return output with the residual connection and the\n",
    "        # newly updated hidden state.\n",
    "        return out + seq, (c_t, n_t, h_t, m_t)\n",
    "\n",
    "class mLSTM(nn.Module):\n",
    "    '''The matrix-Long Short Term Memory (mLSTM) module as\n",
    "    originally introduced in Beck et al. (2024)] see:\n",
    "    (https://arxiv.org/abs/2405.04517).\n",
    "    \n",
    "    This model is a variant of the standard LSTM model and\n",
    "    offers superior memory due to its storing values in a\n",
    "    matrix instead of a scalar. It is fully parallelizable\n",
    "    and updates internal memory with the covariance rule.\n",
    "    '''\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            inp_dim : int,\n",
    "            head_num : int,\n",
    "            head_dim : int,\n",
    "            p_factor : int = 2,\n",
    "            ker_size : int = 4,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.inp_dim = inp_dim\n",
    "        self.head_num = head_num\n",
    "        self.head_dim = head_dim\n",
    "\n",
    "        hid_dim = head_num * head_dim\n",
    "\n",
    "        self.inp_norm = nn.LayerNorm(inp_dim)\n",
    "        self.hid_norm = nn.GroupNorm(head_num, hid_dim)\n",
    "\n",
    "        # NOTE: The factor of two in the output dimension of the up_proj\n",
    "        # is due to the fact that the output needs to branch into two\n",
    "        self.up_l_proj = nn.Linear(inp_dim, int(p_factor * inp_dim))\n",
    "        self.up_r_proj = nn.Linear(inp_dim, hid_dim)\n",
    "        self.down_proj = nn.Linear(hid_dim, inp_dim)\n",
    "\n",
    "        self.causal_conv = CausalConv1d(1, 1, kernel_size=ker_size)\n",
    "\n",
    "        self.skip = nn.Conv1d(int(p_factor * inp_dim), hid_dim, kernel_size=1, bias=False)\n",
    "\n",
    "        self.W_i = nn.Linear(int(p_factor * inp_dim), head_num)\n",
    "        self.W_f = nn.Linear(int(p_factor * inp_dim), head_num)\n",
    "        self.W_o = nn.Linear(int(p_factor * inp_dim), hid_dim)\n",
    "\n",
    "        self.W_q = nn.Linear(int(p_factor * inp_dim), hid_dim)\n",
    "        self.W_k = nn.Linear(int(p_factor * inp_dim), hid_dim)\n",
    "        self.W_v = nn.Linear(int(p_factor * inp_dim), hid_dim)\n",
    "        \n",
    "    @property\n",
    "    def device(self) -> str:\n",
    "        '''Get the device of the model.\n",
    "\n",
    "        Returns:\n",
    "            str: The device of the model.\n",
    "        '''\n",
    "        return next(self.parameters()).device\n",
    "    \n",
    "    def init_hidden(self, bs : int) -> Tuple[Tensor, Tensor, Tensor, Tensor]:\n",
    "        '''Initialize the hidden state of the sLSTM model.\n",
    "\n",
    "        Args:\n",
    "            batch_size (int): The batch size of the input sequence.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Tensor, Tensor, Tensor, Tensor]: The hidden state tuple containing the cell state,\n",
    "                normalizer state, hidden state, and stabilizer state.\n",
    "        '''\n",
    "\n",
    "        c_0 = torch.zeros(bs, self.head_num, self.head_dim, self.head_dim, device=self.device)\n",
    "        n_0 = torch.ones (bs, self.head_num, self.head_dim               , device=self.device) \n",
    "        m_0 = torch.zeros(bs, self.head_num                              , device=self.device)\n",
    "\n",
    "        return c_0, n_0, m_0\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            seq: Tensor,\n",
    "            hid: Tuple[Tensor, Tensor],\n",
    "    ) -> Tuple[Tensor, Tuple[Tensor, Tensor]]:\n",
    "        '''_summary_\n",
    "\n",
    "        Args:\n",
    "            seq (Tensor): _description_\n",
    "            hid (Tuple[Tensor, Tensor]): _description_\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Tensor, Tuple[Tensor, Tensor]]: _description_\n",
    "        '''\n",
    "\n",
    "        # Separate the hidden (previous) state into the cell state,\n",
    "        # the normalizer state, the hidden state, and the stabilizer state.\n",
    "        c_tm1, n_tm1, m_tm1 = hid\n",
    "\n",
    "        x_n : Tensor = self.inp_norm(seq) # shape: b i\n",
    "\n",
    "        x_t = self.up_l_proj(x_n) # shape: b (i * p_factor)\n",
    "        r_t = self.up_r_proj(x_n) # shape: b (h d)\n",
    "\n",
    "        # Compute the causal convolutional input (to be \n",
    "        # used for the query and key gates)\n",
    "        x_c = self.causal_conv(x_t) # shape: b 1 (i * p_factor)\n",
    "        x_c = silu(x_c).squeeze()   # shape: b (i * p_factor)\n",
    "\n",
    "        q_t = rearrange(self.W_q(x_c), 'b (h d) -> b h d', h=self.head_num)\n",
    "        k_t = rearrange(self.W_k(x_c), 'b (h d) -> b h d', h=self.head_num) / sqrt(self.head_dim)\n",
    "        v_t = rearrange(self.W_v(x_t), 'b (h d) -> b h d', h=self.head_num)\n",
    "\n",
    "        i_t: Tensor = self.W_i(x_c) # shape: b h\n",
    "        f_t: Tensor = self.W_f(x_c) # shape: b h\n",
    "        o_t: Tensor = self.W_o(x_t) # shape: b (h d)\n",
    "\n",
    "        # Compute the gated outputs for the newly computed inputs\n",
    "        m_t = torch.max(f_t + m_tm1, i_t)\n",
    "\n",
    "        i_t = exp(i_t - m_t)         # Eq. (25) in ref. paper\n",
    "        f_t = exp(f_t - m_t + m_tm1) # Eq. (26) in ref. paper\n",
    "        o_t = sigmoid(o_t)           # Eq. (27) in ref. paper\n",
    "\n",
    "        # Update the internal states of the model\n",
    "        c_t = enlarge_as(f_t, c_tm1) * c_tm1 + enlarge_as(i_t, c_tm1) * einsum(v_t, k_t, 'b h d, b h p -> b h d p')\n",
    "        n_t = enlarge_as(f_t, n_tm1) * n_tm1 + enlarge_as(i_t, k_t)   * k_t\n",
    "        h_t = o_t * rearrange(\n",
    "            einsum(c_t, q_t, 'b h d p, b h p -> b h d') /\n",
    "            einsum(n_t, q_t, 'b h d, b h d -> b h').clamp(min=1).unsqueeze(-1),\n",
    "            'b h d -> b (h d)'\n",
    "        ) # Eq. (21) in ref. paper\n",
    "\n",
    "        x_c = rearrange(x_c, 'b i -> b i 1')\n",
    "        out = self.hid_norm(h_t) + self.skip(x_c).squeeze() # shape: b (h d)\n",
    "        out = out * silu(r_t)                               # shape: b (h d)\n",
    "        out = self.down_proj(out)                           # shape: h i\n",
    "\n",
    "        # Return output with the residual connection and the\n",
    "        # newly updated hidden state.\n",
    "        return out + seq, (c_t, n_t, m_t)"
   ],
   "id": "c497bedaf67f9808",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T18:54:58.884886Z",
     "start_time": "2024-06-01T18:54:58.882048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# \n",
    "# from src.models.xlstm.m_lstm import mLSTM\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Accuracy, F1Score\n",
    "# \n",
    "# \n",
    "# class xLSTMBlock(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, num_layers, dropout=0.0, bidirectional=False, lstm_type=\"slstm\"):\n",
    "#         super(xLSTMBlock, self).__init__()\n",
    "#         self.input_size = input_size\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "#         self.dropout = dropout\n",
    "#         self.bidirectional = bidirectional\n",
    "#         self.lstm_type = lstm_type\n",
    "# \n",
    "#         if lstm_type == \"slstm\":\n",
    "#             self.lstm = sLSTM(input_size, hidden_size, num_layers, dropout)\n",
    "#         elif lstm_type == \"mlstm\":\n",
    "#             print(\"Warning: mLSTM is not working yet.\")\n",
    "#             self.lstm = mLSTM(input_size, hidden_size, num_layers, dropout)\n",
    "#         else:\n",
    "#             raise ValueError(f\"Invalid LSTM type: {lstm_type}\")\n",
    "# \n",
    "#         self.norm = nn.LayerNorm(input_size)\n",
    "#         self.activation = nn.GELU()\n",
    "#         self.dropout_layer = nn.Dropout(dropout)\n",
    "# \n",
    "#         if bidirectional:\n",
    "#             self.proj = nn.Linear(2 * hidden_size, input_size)\n",
    "#         else:\n",
    "#             self.proj = nn.Linear(hidden_size, input_size)\n",
    "# \n",
    "#         # print shapes\n",
    "#         # print(f\"input_size: {input_size}\")\n",
    "#         # print(f\"hidden_size: {hidden_size}\")\n",
    "#         # print(f\"num_layers: {num_layers}\")\n",
    "#         # print(f\"dropout: {dropout}\")\n",
    "#         # print(f\"proj: {self.proj}\")\n",
    "# \n",
    "#         self.reset_parameters()\n",
    "# \n",
    "#     def reset_parameters(self):\n",
    "#         nn.init.xavier_uniform_(self.proj.weight)\n",
    "#         nn.init.zeros_(self.proj.bias)\n",
    "# \n",
    "#     def forward(self, input_seq, hidden_state=None):\n",
    "#         lstm_output, hidden_state = self.lstm(input_seq, hidden_state)\n",
    "#         if self.lstm_type == \"slstm\":\n",
    "#             hidden_state = [[hidden_state[i][0].detach(), hidden_state[i][1].detach()] for i in range(len(hidden_state))]\n",
    "# \n",
    "#         if self.bidirectional:\n",
    "#             lstm_output = torch.cat((lstm_output[:, :, :self.hidden_size], lstm_output[:, :, self.hidden_size:]), dim=-1)\n",
    "# \n",
    "#         output = self.activation(self.proj(lstm_output))\n",
    "#         output = self.norm(output + input_seq)\n",
    "#         output = self.dropout_layer(output)\n",
    "# \n",
    "#         return output, hidden_state\n",
    "# \n",
    "# class xLSTM(L.LightningModule):\n",
    "#     def __init__(self, optimizer, scheduler, input_size, hidden_size, output_size, num_layers, num_blocks,\n",
    "#                  dropout=0.0, bidirectional=False, lstm_type=\"slstm\"):\n",
    "#         super().__init__()\n",
    "#         self.save_hyperparameters()\n",
    "# \n",
    "#         self.accuracy = Accuracy(task='multiclass', num_classes=output_size)\n",
    "#         self.f1_score = F1Score(num_classes=output_size, average='weighted', task='multiclass')\n",
    "#         self.num_blocks = num_blocks\n",
    "#         self.lstm_type = lstm_type\n",
    "# \n",
    "#         self.blocks = nn.ModuleList([\n",
    "#             xLSTMBlock(input_size, hidden_size, num_layers,\n",
    "#                        dropout, bidirectional, lstm_type)\n",
    "#             for i in range(num_blocks)\n",
    "#         ])\n",
    "# \n",
    "#         self.output_layer = nn.Linear(input_size, output_size)\n",
    "# \n",
    "#     def forward(self, input_seq, hidden_states=None):\n",
    "#         if hidden_states is None:\n",
    "#             hidden_states = [None] * self.num_blocks\n",
    "# \n",
    "#         output_seq = input_seq\n",
    "#         for i, block in enumerate(self.blocks):\n",
    "#             output_seq, hidden_state = block(output_seq, hidden_states[i])\n",
    "#             if self.lstm_type == \"slstm\":\n",
    "#                 hidden_states[i] = [[hidden_state[j][0].detach(), hidden_state[j][1].detach()] for j in range(len(hidden_state))]\n",
    "#             else:\n",
    "#                 hidden_states[i] = hidden_state\n",
    "# \n",
    "#         output_seq = output_seq[:, -1, :]\n",
    "#         output_seq = self.output_layer(output_seq)\n",
    "#         return output_seq\n",
    "# \n",
    "#     def _shared_step(self, batch, batch_idx):\n",
    "#         x, y = batch\n",
    "#         logits = self(x)\n",
    "#         preds = torch.argmax(logits, dim=1)\n",
    "#         y = torch.argmax(y, dim=1)\n",
    "#         print(logits.shape, y.shape)\n",
    "#         loss = F.cross_entropy(logits, y)\n",
    "#         acc = self.accuracy(preds, y)\n",
    "#         f1 = self.f1_score(preds, y)\n",
    "#         return loss, acc, f1\n",
    "# \n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         loss, acc, f1 = self._shared_step(batch, batch_idx)\n",
    "#         self.log_dict({\"train_loss\": loss, \"train_acc\": acc, \"train_f1\": f1}, prog_bar=True)\n",
    "#         return loss\n",
    "# \n",
    "#     def validation_step(self, batch, batch_idx):\n",
    "#         loss, acc, f1 = self._shared_step(batch, batch_idx)\n",
    "#         self.log_dict({\"val_loss\": loss, \"val_acc\": acc, \"val_f1\": f1}, prog_bar=True)\n",
    "#         return loss\n",
    "# \n",
    "#     def configure_optimizers(self):\n",
    "#         optimizer = self.hparams.optimizer(params=self.trainer.model.parameters())\n",
    "#         return optimizer\n",
    "#         # scheduler = self.hparams.scheduler(optimizer, T_max=10)\n",
    "#         # \n",
    "#         # return {\n",
    "#         #     \"optimizer\": optimizer,\n",
    "#         #     \"lr_scheduler\": {\n",
    "#         #         \"scheduler\": scheduler,\n",
    "#         #         \"interval\": \"epoch\",\n",
    "#         #         \"frequency\": 1,\n",
    "#         #     }\n",
    "#         # }"
   ],
   "id": "65d54d779385e3e3",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T18:54:58.893547Z",
     "start_time": "2024-06-01T18:54:58.886355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from warnings import warn\n",
    "from lightning import LightningModule\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.optim import AdamW\n",
    "from torch.optim import Optimizer\n",
    "from torch.nn .functional import softmax\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "from typing import Any, Dict, Generator, List, Tuple, Callable, Iterable\n",
    "\n",
    "from itertools import repeat\n",
    "from einops import rearrange\n",
    "\n",
    "\n",
    "\n",
    "OptimizerCallable = Callable[[Iterable], Optimizer]\n",
    "\n",
    "class xLSTM(LightningModule):\n",
    "    '''The extended Long Short Term Memory (xLSTM) module as\n",
    "    originally introduced in Beck et al. (2024)] see:\n",
    "    (https://arxiv.org/abs/2405.04517).\n",
    "    \n",
    "    This model stacks sLSTM and mLSTM modules with residual\n",
    "    connections and offers superior memory and performance\n",
    "    compared to the standard LSTM model, achieving competitive\n",
    "    or better performance and scaling than Transformer models\n",
    "    or State-Space models.\n",
    "    '''\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_layers : int,\n",
    "            signature : Tuple[int, int],\n",
    "            inp_dim : int,\n",
    "            head_dim : int,\n",
    "            head_num : int,\n",
    "            output_size : int,\n",
    "            p_factor : Tuple[float, float] = (2, 4/3),\n",
    "            ker_size : int = 4,\n",
    "            optimizer : OptimizerCallable = AdamW,\n",
    "            inference_kw: Dict[str, Any] = {}\n",
    "    ) -> None:\n",
    "        '''Initialize the LLM model.\n",
    "\n",
    "        Args:\n",
    "            vocab_size (int): The size of the vocabulary.\n",
    "            num_layers (int): The number of layers in the LLM model.\n",
    "            signature (Tuple[int, int]): The signature of the LLM model,\n",
    "                which represents the ration of the mLSTM-to-sLSTM blocks.\n",
    "            inp_dim (int): The dimension of the input tokens.\n",
    "            head_dim (int): The dimension of each attention head.\n",
    "            head_num (int): The number of attention heads.\n",
    "            p_factor (Tuple[float, float], optional): The expansion factor\n",
    "                for the MLP projection in the m|s-LSTM blocks. Defaults to (2, 4/3).\n",
    "            ker_size (int, optional): The kernel size for the causal convolutional layers.\n",
    "                Defaults to 4.\n",
    "                \n",
    "            kwargs: Additional keyword arguments used at inference time (see relevant\n",
    "                arguments of the generate method).\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.accuracy = Accuracy(task='multiclass', num_classes=output_size)\n",
    "        self.f1_score = F1Score(num_classes=output_size, average='weighted', task='multiclass')\n",
    "        self.optimizer = optimizer\n",
    "        self.inference_kw = inference_kw\n",
    "\n",
    "        m_factor, s_factor = p_factor\n",
    "\n",
    "        mlstm_par = {\n",
    "            'inp_dim' : inp_dim,\n",
    "            'head_dim' : head_dim,\n",
    "            'head_num' : head_num,\n",
    "            'p_factor' : m_factor,\n",
    "            'ker_size' : ker_size,\n",
    "        }\n",
    "\n",
    "        slstm_par = {\n",
    "            'inp_dim' : inp_dim,\n",
    "            'head_dim' : head_dim,\n",
    "            'head_num' : head_num,\n",
    "            'p_factor' : s_factor,\n",
    "            'ker_size' : ker_size,\n",
    "        }\n",
    "\n",
    "        m_num, s_num = signature\n",
    "        which = [True] * m_num + [False] * s_num\n",
    "\n",
    "        self.model : List[mLSTM | sLSTM] = nn.ModuleList([\n",
    "            mLSTM(**mlstm_par) if w else sLSTM(**slstm_par)\n",
    "            for w, _ in zip(repeat(which), range(num_layers))\n",
    "        ])\n",
    "\n",
    "        self.head = nn.Linear(inp_dim, output_size, bias=False)\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            seq: Tensor,\n",
    "            hid: Hidden | None = None,\n",
    "            batch_first : bool = True,\n",
    "    ) -> Tuple[Tensor, Hidden]:\n",
    "        '''Forward pass of the xLSTM model.\n",
    "\n",
    "        Args:\n",
    "            tok (Tensor): Input tensor representing the sequence tokens.\n",
    "                Expected shape: (batch, seq_len) if batch_first=True,\n",
    "                else (seq_len, batch).\n",
    "            hid (Hidden, optional): Cache object for storing intermediate hidden\n",
    "                values of the m|s-LSTM blocks of the model. If None, the hidden\n",
    "                states are initialized by the models. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Tensor, Hidden]: Returns tensor of predicted logits of shape\n",
    "                (batch, seq_len, vocab_size) if batch_first=True or of shape\n",
    "                (seq_len, batch, vocab_size) if batch_first=False, and the\n",
    "                updated hidden model states.\n",
    "        '''\n",
    "\n",
    "\n",
    "        if batch_first: seq = rearrange(seq, 'b s i -> s b i')\n",
    "        if hid is None: hid = [l.init_hidden(seq.size(1)) for l in self.model]\n",
    "\n",
    "        # Pass the sequence through the mLSTM and sLSTM blocks\n",
    "        out = []\n",
    "        for inp in seq:\n",
    "            # Compute model output and update the hidden states\n",
    "            for i, lstm in enumerate(self.model):\n",
    "                inp, hid[i] = lstm(inp, hid[i])\n",
    "\n",
    "            out.append(inp)\n",
    "\n",
    "        out = torch.stack(out, dim=1 if batch_first else 0)\n",
    "        out = self.head(out)\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        return out, hid\n",
    "\n",
    "    def _shared_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits, hid = self(x)\n",
    "        preds = torch.argmax(logits, dim=1).float()\n",
    "        loss = F.cross_entropy(logits, y.float())\n",
    "        y = torch.argmax(y, dim=1).float()\n",
    "        acc = self.accuracy(preds, y)\n",
    "        f1 = self.f1_score(preds, y)\n",
    "        return loss, acc, f1\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, acc, f1 = self._shared_step(batch, batch_idx)\n",
    "        self.log_dict({\"train_loss\": loss, \"train_acc\": acc, \"train_f1\": f1}, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, acc, f1 = self._shared_step(batch, batch_idx)\n",
    "        self.log_dict({\"val_loss\": loss, \"val_acc\": acc, \"val_f1\": f1}, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self) -> Optimizer:\n",
    "        optim = self.optimizer(\n",
    "            self.parameters(),\n",
    "        )\n",
    "\n",
    "        return optim"
   ],
   "id": "2fde12e154361ae2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T19:35:48.176258Z",
     "start_time": "2024-06-12T19:35:46.639960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.data.dataset import SensorDataModule\n",
    "\n",
    "dataset = SensorDataModule(32, \"../data/partitions\", k_folds=0)\n",
    "dataset.setup()\n",
    "\n",
    "train_dataloader, val_dataloader = dataset.train_dataloader(), dataset.val_dataloader()"
   ],
   "id": "70e813009c195fd7",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Accuracy, F1Score\n\u001B[1;32m      4\u001B[0m dataset \u001B[38;5;241m=\u001B[39m SensorDataModule(\u001B[38;5;241m32\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../data/partitions\u001B[39m\u001B[38;5;124m\"\u001B[39m, k_folds\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m----> 5\u001B[0m \u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m train_dataloader, val_dataloader \u001B[38;5;241m=\u001B[39m dataset\u001B[38;5;241m.\u001B[39mtrain_dataloader(), dataset\u001B[38;5;241m.\u001B[39mval_dataloader()\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/src/data/dataset.py:109\u001B[0m, in \u001B[0;36mSensorDataModule.setup\u001B[0;34m(self, stage)\u001B[0m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_fold \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mk_folds:\n\u001B[1;32m    106\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCurrent fold is not set for cross-validation. Please set the fold before setup.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    108\u001B[0m partition \u001B[38;5;241m=\u001B[39m data_list \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mk_folds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \\\n\u001B[0;32m--> 109\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m \u001B[43mdata_list\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfolds\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcurrent_fold\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_data \u001B[38;5;241m=\u001B[39m partition\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    112\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mval_data \u001B[38;5;241m=\u001B[39m partition\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalidate\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: list indices must be integers or slices, not NoneType"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T18:55:01.064576Z",
     "start_time": "2024-06-01T18:55:00.987125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = L.Trainer(max_epochs=5,\n",
    "                     accelerator='mps',\n",
    "                     log_every_n_steps=10)\n"
   ],
   "id": "168af7d8910b5cba",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/dmnk/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T18:55:27.805075Z",
     "start_time": "2024-06-01T18:55:01.065267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "batch = next(iter(train_dataloader))\n"
   ],
   "id": "b7bdb22636a2eb46",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T18:55:27.813388Z",
     "start_time": "2024-06-01T18:55:27.807684Z"
    }
   },
   "cell_type": "code",
   "source": "batch[0].shape",
   "id": "9dcdfd1176c3fc89",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 251, 16])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T18:55:27.828865Z",
     "start_time": "2024-06-01T18:55:27.814355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = xLSTM(num_layers=3,\n",
    "                         signature=(2, 1),\n",
    "                         inp_dim=16,\n",
    "                         head_dim=32,\n",
    "                         head_num=4,\n",
    "                         output_size=dataset.num_classes,\n",
    "                         p_factor=(2, 4/3),\n",
    "                         ker_size=4, optimizer=torch.optim.AdamW) "
   ],
   "id": "418420b453decaa4",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T18:55:27.832646Z",
     "start_time": "2024-06-01T18:55:27.830354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model = xLSTM(input_size=16,\n",
    "#                          hidden_size=32,\n",
    "#                          output_size=dataset.num_classes,\n",
    "#                          num_layers=3,\n",
    "#                          dropout=0.1,\n",
    "#                          num_blocks=2, optimizer=torch.optim.AdamW, scheduler=torch.optim.lr_scheduler.CosineAnnealingLR,\n",
    "#               lstm_type=\"slstm\")\n"
   ],
   "id": "7710f4c102c8d486",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T18:55:29.898133Z",
     "start_time": "2024-06-01T18:55:27.833329Z"
    }
   },
   "cell_type": "code",
   "source": "model.training_step(batch, 0)",
   "id": "3433ce8fcfd1a4fe",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmnk/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py:436: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.8622, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T18:55:29.909031Z",
     "start_time": "2024-06-01T18:55:29.900694Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "106c2bcef2624574",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-01T18:55:29.914003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer.fit(model, train_dataloader, val_dataloader)\n",
    "\n"
   ],
   "id": "db75c1eeef06bc81",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type               | Params\n",
      "------------------------------------------------\n",
      "0 | accuracy | MulticlassAccuracy | 0     \n",
      "1 | f1_score | MulticlassF1Score  | 0     \n",
      "2 | model    | ModuleList         | 79.0 K\n",
      "3 | head     | Linear             | 80    \n",
      "------------------------------------------------\n",
      "79.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "79.1 K    Total params\n",
      "0.316     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd587b87b7c743cb97222f62c08a7e40"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50fea28ad5ec4a0ba6760b253898d44f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 80189) is killed by signal: Interrupt: 2. ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:309\u001B[0m, in \u001B[0;36m_call_strategy_hook\u001B[0;34m(trainer, hook_name, *args, **kwargs)\u001B[0m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[Strategy]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 309\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py:213\u001B[0m, in \u001B[0;36mStrategy.backward\u001B[0;34m(self, closure_loss, optimizer, *args, **kwargs)\u001B[0m\n\u001B[1;32m    211\u001B[0m closure_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprecision_plugin\u001B[38;5;241m.\u001B[39mpre_backward(closure_loss, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module)\n\u001B[0;32m--> 213\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprecision_plugin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclosure_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlightning_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    215\u001B[0m closure_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprecision_plugin\u001B[38;5;241m.\u001B[39mpost_backward(closure_loss, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module)\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py:72\u001B[0m, in \u001B[0;36mPrecision.backward\u001B[0;34m(self, tensor, model, optimizer, *args, **kwargs)\u001B[0m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Performs the actual backpropagation.\u001B[39;00m\n\u001B[1;32m     62\u001B[0m \n\u001B[1;32m     63\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     70\u001B[0m \n\u001B[1;32m     71\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m---> 72\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py:1090\u001B[0m, in \u001B[0;36mLightningModule.backward\u001B[0;34m(self, loss, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1089\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1090\u001B[0m     \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/torch/_tensor.py:525\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    517\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    518\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    523\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    524\u001B[0m     )\n\u001B[0;32m--> 525\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    266\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 267\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    743\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 744\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    745\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    746\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    747\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloader\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:544\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    542\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n\u001B[1;32m    543\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 544\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    545\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[1;32m    546\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:44\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     43\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[1;32m     47\u001B[0m     _call_teardown_hook(trainer)\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:580\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    573\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    574\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[1;32m    575\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n\u001B[1;32m    576\u001B[0m     ckpt_path,\n\u001B[1;32m    577\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    578\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    579\u001B[0m )\n\u001B[0;32m--> 580\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    582\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[1;32m    583\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:987\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n\u001B[1;32m    982\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_signal_connector\u001B[38;5;241m.\u001B[39mregister_signal_handlers()\n\u001B[1;32m    984\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    985\u001B[0m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n\u001B[1;32m    986\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m--> 987\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    989\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    990\u001B[0m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n\u001B[1;32m    991\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    992\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1033\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1031\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_sanity_check()\n\u001B[1;32m   1032\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n\u001B[0;32m-> 1033\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1034\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1035\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnexpected state \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:205\u001B[0m, in \u001B[0;36m_FitLoop.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    203\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    204\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_start()\n\u001B[0;32m--> 205\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madvance\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    206\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end()\n\u001B[1;32m    207\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_restarting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:363\u001B[0m, in \u001B[0;36m_FitLoop.advance\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    361\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_training_epoch\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    362\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_fetcher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 363\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepoch_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_fetcher\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py:140\u001B[0m, in \u001B[0;36m_TrainingEpochLoop.run\u001B[0;34m(self, data_fetcher)\u001B[0m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdone:\n\u001B[1;32m    139\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 140\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madvance\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_fetcher\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    141\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end(data_fetcher)\n\u001B[1;32m    142\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_restarting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py:250\u001B[0m, in \u001B[0;36m_TrainingEpochLoop.advance\u001B[0;34m(self, data_fetcher)\u001B[0m\n\u001B[1;32m    247\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_training_batch\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    248\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mlightning_module\u001B[38;5;241m.\u001B[39mautomatic_optimization:\n\u001B[1;32m    249\u001B[0m         \u001B[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001B[39;00m\n\u001B[0;32m--> 250\u001B[0m         batch_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautomatic_optimization\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizers\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    251\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    252\u001B[0m         batch_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmanual_optimization\u001B[38;5;241m.\u001B[39mrun(kwargs)\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:190\u001B[0m, in \u001B[0;36m_AutomaticOptimization.run\u001B[0;34m(self, optimizer, batch_idx, kwargs)\u001B[0m\n\u001B[1;32m    183\u001B[0m         closure()\n\u001B[1;32m    185\u001B[0m \u001B[38;5;66;03m# ------------------------------\u001B[39;00m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;66;03m# BACKWARD PASS\u001B[39;00m\n\u001B[1;32m    187\u001B[0m \u001B[38;5;66;03m# ------------------------------\u001B[39;00m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;66;03m# gradient update with accumulated gradients\u001B[39;00m\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 190\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_optimizer_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    192\u001B[0m result \u001B[38;5;241m=\u001B[39m closure\u001B[38;5;241m.\u001B[39mconsume_result()\n\u001B[1;32m    193\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result\u001B[38;5;241m.\u001B[39mloss \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:268\u001B[0m, in \u001B[0;36m_AutomaticOptimization._optimizer_step\u001B[0;34m(self, batch_idx, train_step_and_backward_closure)\u001B[0m\n\u001B[1;32m    265\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptim_progress\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mstep\u001B[38;5;241m.\u001B[39mincrement_ready()\n\u001B[1;32m    267\u001B[0m \u001B[38;5;66;03m# model hook\u001B[39;00m\n\u001B[0;32m--> 268\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_lightning_module_hook\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moptimizer_step\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcurrent_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_step_and_backward_closure\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m should_accumulate:\n\u001B[1;32m    278\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptim_progress\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mstep\u001B[38;5;241m.\u001B[39mincrement_completed()\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:157\u001B[0m, in \u001B[0;36m_call_lightning_module_hook\u001B[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001B[0m\n\u001B[1;32m    154\u001B[0m pl_module\u001B[38;5;241m.\u001B[39m_current_fx_name \u001B[38;5;241m=\u001B[39m hook_name\n\u001B[1;32m    156\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[LightningModule]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpl_module\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 157\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n\u001B[1;32m    160\u001B[0m pl_module\u001B[38;5;241m.\u001B[39m_current_fx_name \u001B[38;5;241m=\u001B[39m prev_fx_name\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py:1303\u001B[0m, in \u001B[0;36mLightningModule.optimizer_step\u001B[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001B[0m\n\u001B[1;32m   1264\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimizer_step\u001B[39m(\n\u001B[1;32m   1265\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1266\u001B[0m     epoch: \u001B[38;5;28mint\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1269\u001B[0m     optimizer_closure: Optional[Callable[[], Any]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1270\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1271\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001B[39;00m\n\u001B[1;32m   1272\u001B[0m \u001B[38;5;124;03m    the optimizer.\u001B[39;00m\n\u001B[1;32m   1273\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1301\u001B[0m \n\u001B[1;32m   1302\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1303\u001B[0m     \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclosure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer_closure\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py:152\u001B[0m, in \u001B[0;36mLightningOptimizer.step\u001B[0;34m(self, closure, **kwargs)\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MisconfigurationException(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_strategy \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 152\u001B[0m step_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_strategy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer_step\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_on_after_step()\n\u001B[1;32m    156\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m step_output\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py:239\u001B[0m, in \u001B[0;36mStrategy.optimizer_step\u001B[0;34m(self, optimizer, closure, model, **kwargs)\u001B[0m\n\u001B[1;32m    237\u001B[0m \u001B[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001B[39;00m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(model, pl\u001B[38;5;241m.\u001B[39mLightningModule)\n\u001B[0;32m--> 239\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprecision_plugin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclosure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclosure\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py:122\u001B[0m, in \u001B[0;36mPrecision.optimizer_step\u001B[0;34m(self, optimizer, model, closure, **kwargs)\u001B[0m\n\u001B[1;32m    120\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Hook to run the optimizer step.\"\"\"\u001B[39;00m\n\u001B[1;32m    121\u001B[0m closure \u001B[38;5;241m=\u001B[39m partial(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wrap_closure, model, optimizer, closure)\n\u001B[0;32m--> 122\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclosure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclosure\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py:391\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    386\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    387\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    388\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    389\u001B[0m             )\n\u001B[0;32m--> 391\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    392\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    394\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     74\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     75\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[0;32m---> 76\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     78\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/torch/optim/adamw.py:165\u001B[0m, in \u001B[0;36mAdamW.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m closure \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    164\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39menable_grad():\n\u001B[0;32m--> 165\u001B[0m         loss \u001B[38;5;241m=\u001B[39m \u001B[43mclosure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m group \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparam_groups:\n\u001B[1;32m    168\u001B[0m     params_with_grad \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py:108\u001B[0m, in \u001B[0;36mPrecision._wrap_closure\u001B[0;34m(self, model, optimizer, closure)\u001B[0m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_wrap_closure\u001B[39m(\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     97\u001B[0m     model: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpl.LightningModule\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     98\u001B[0m     optimizer: Optimizer,\n\u001B[1;32m     99\u001B[0m     closure: Callable[[], Any],\n\u001B[1;32m    100\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    101\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001B[39;00m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;124;03m    hook is called.\u001B[39;00m\n\u001B[1;32m    103\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    106\u001B[0m \n\u001B[1;32m    107\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 108\u001B[0m     closure_result \u001B[38;5;241m=\u001B[39m \u001B[43mclosure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    109\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_after_closure(model, optimizer)\n\u001B[1;32m    110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m closure_result\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:144\u001B[0m, in \u001B[0;36mClosure.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    142\u001B[0m \u001B[38;5;129m@override\u001B[39m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[Tensor]:\n\u001B[0;32m--> 144\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclosure\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\u001B[38;5;241m.\u001B[39mloss\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:138\u001B[0m, in \u001B[0;36mClosure.closure\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    135\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_zero_grad_fn()\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m step_output\u001B[38;5;241m.\u001B[39mclosure_loss \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 138\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backward_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep_output\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclosure_loss\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m step_output\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:239\u001B[0m, in \u001B[0;36m_AutomaticOptimization._make_backward_fn.<locals>.backward_fn\u001B[0;34m(loss)\u001B[0m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbackward_fn\u001B[39m(loss: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 239\u001B[0m     \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_strategy_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbackward\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:308\u001B[0m, in \u001B[0;36m_call_strategy_hook\u001B[0;34m(trainer, hook_name, *args, **kwargs)\u001B[0m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(fn):\n\u001B[1;32m    306\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 308\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprofiler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprofile\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m[Strategy]\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstrategy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__class__\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__name__\u001B[39;49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mhook_name\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    309\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Cellar/python@3.11/3.11.9/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py:141\u001B[0m, in \u001B[0;36m_GeneratorContextManager.__exit__\u001B[0;34m(self, typ, value, traceback)\u001B[0m\n\u001B[1;32m    138\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[1;32m    139\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerator didn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt yield\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 141\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__exit__\u001B[39m(\u001B[38;5;28mself\u001B[39m, typ, value, traceback):\n\u001B[1;32m    142\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m typ \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    143\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001B[0m, in \u001B[0;36m_set_SIGCHLD_handler.<locals>.handler\u001B[0;34m(signum, frame)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhandler\u001B[39m(signum, frame):\n\u001B[1;32m     64\u001B[0m     \u001B[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001B[39;00m\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;66;03m# Python can still get and update the process status successfully.\u001B[39;00m\n\u001B[0;32m---> 66\u001B[0m     \u001B[43m_error_if_any_worker_fails\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     67\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m previous_handler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     68\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(previous_handler)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: DataLoader worker (pid 80189) is killed by signal: Interrupt: 2. "
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T19:46:48.139374Z",
     "start_time": "2024-06-12T19:46:47.530183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import lightning as L\n",
    "from src.data.dataset import SensorDataModule\n",
    "\n",
    "dataset = SensorDataModule(32, \"../data/partitions\")\n",
    "dataset.setup()\n",
    "\n",
    "train_dataloader, val_dataloader = dataset.train_dataloader(), dataset.val_dataloader()\n",
    "train_dataloader"
   ],
   "id": "aa27075df5ded16c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x335e35b50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T19:46:35.495113Z",
     "start_time": "2024-06-12T19:46:34.548028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Accuracy, F1Score\n"
   ],
   "id": "7fe5fdfcacdefc5c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T19:46:36.161354Z",
     "start_time": "2024-06-12T19:46:36.090285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "\n",
    "batch[0].shape"
   ],
   "id": "6683681a8d004c73",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(\u001B[43mtrain_dataloader\u001B[49m))\n\u001B[1;32m      3\u001B[0m batch[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mshape\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train_dataloader' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T19:46:37.649282Z",
     "start_time": "2024-06-12T19:46:37.228727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# path/filename: /path/to/your_pytorch_lightning_wrapper.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import lightning as pl\n",
    "from xlstm import (\n",
    "    xLSTMBlockStack,\n",
    "    xLSTMBlockStackConfig,\n",
    "    mLSTMBlockConfig,\n",
    "    mLSTMLayerConfig,\n",
    "    sLSTMBlockConfig,\n",
    "    sLSTMLayerConfig,\n",
    "    FeedForwardConfig,\n",
    ")\n",
    "\n",
    "class XLSTMPLModule(pl.LightningModule):\n",
    "    def __init__(self, context_length, num_blocks, embedding_dim, slstm_at, mlstm_config, slstm_config, num_classes):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()  # Saves all initialization parameters for easy access and reproducibility\n",
    "        self.model = xLSTMBlockStack(\n",
    "            xLSTMBlockStackConfig(\n",
    "                mlstm_block=mlstm_config,\n",
    "                slstm_block=slstm_config,\n",
    "                context_length=context_length,\n",
    "                num_blocks=num_blocks,\n",
    "                embedding_dim=embedding_dim,\n",
    "                slstm_at=slstm_at,\n",
    "            )\n",
    "        )\n",
    "        self.classifier = nn.Linear(embedding_dim, num_classes)  # Classifier layer\n",
    "        self.accuracy = Accuracy(task='multiclass', num_classes=num_classes)\n",
    "        self.f1_score = F1Score(num_classes=num_classes, average='weighted', task='multiclass')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.model(x)\n",
    "        output = self.classifier(features[:, -1, :]) \n",
    "        return output\n",
    "\n",
    "    def _shared_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        preds = torch.argmax(logits, dim=1).float()\n",
    "        loss = F.cross_entropy(logits, y.float())\n",
    "        y = torch.argmax(y, dim=1).float()\n",
    "        acc = self.accuracy(preds, y)\n",
    "        f1 = self.f1_score(preds, y)\n",
    "        return loss, acc, f1\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, acc, f1 = self._shared_step(batch, batch_idx)\n",
    "        self.log_dict({\"train_loss\": loss, \"train_acc\": acc, \"train_f1\": f1}, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, acc, f1 = self._shared_step(batch, batch_idx)\n",
    "        self.log_dict({\"val_loss\": loss, \"val_acc\": acc, \"val_f1\": f1}, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "# Configurations for the mLSTM and sLSTM blocks\n",
    "mlstm_config = mLSTMBlockConfig(\n",
    "    mlstm=mLSTMLayerConfig(\n",
    "        conv1d_kernel_size=4, qkv_proj_blocksize=4, num_heads=4\n",
    "    )\n",
    ")\n",
    "\n",
    "slstm_config = sLSTMBlockConfig(\n",
    "    slstm=sLSTMLayerConfig(\n",
    "        backend=\"vanilla\",\n",
    "        num_heads=4,\n",
    "        conv1d_kernel_size=4,\n",
    "    ),\n",
    "    feedforward=FeedForwardConfig(proj_factor=1.3, act_fn=\"gelu\"),\n",
    ")\n",
    "\n",
    "# Initialization with the number of classes for the classification task\n",
    "pl_module = XLSTMPLModule(\n",
    "    context_length=251,\n",
    "    num_blocks=7,\n",
    "    embedding_dim=16,\n",
    "    slstm_at=[0],\n",
    "    mlstm_config=mlstm_config,\n",
    "    slstm_config=slstm_config,\n",
    "    num_classes=5\n",
    ")\n"
   ],
   "id": "da8a0845aab1dd40",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T19:46:39.062250Z",
     "start_time": "2024-06-12T19:46:39.033198Z"
    }
   },
   "cell_type": "code",
   "source": "pl_module.training_step(batch, 0)\n",
   "id": "9798be2024d3eb4c",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m pl_module\u001B[38;5;241m.\u001B[39mtraining_step(\u001B[43mbatch\u001B[49m, \u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'batch' is not defined"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T19:55:07.372531Z",
     "start_time": "2024-06-12T19:46:53.578111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = L.Trainer(max_epochs=20,\n",
    "                    accelerator='mps',\n",
    "                    log_every_n_steps=10)\n",
    "\n",
    "trainer.fit(pl_module, train_dataloader, val_dataloader)\n"
   ],
   "id": "e7479cbd65008fe0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | model      | xLSTMBlockStack    | 38.9 K\n",
      "1 | classifier | Linear             | 85    \n",
      "2 | accuracy   | MulticlassAccuracy | 0     \n",
      "3 | f1_score   | MulticlassF1Score  | 0     \n",
      "--------------------------------------------------\n",
      "39.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "39.0 K    Total params\n",
      "0.156     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77f45207121c4de78aad803725e89b31"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "efb1f30ec8b341c0a2f8f1658b38dec7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c225efd817f42fa9d2c6008d917e16f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7bebd12b3c1f4a1abe0483566a072e78"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4c5136c3dff5402fbb6f20088704ced7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2041cd5edfe4a978652747c25c1a2f6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "833663c254dc4a89b22df86813576b47"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "31d1870bab924ee18a4045b5fcfc6ec4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f68e68e41b84e67803de887cd0e2f5e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35cfc49fb84a41e7ac048bed26e1da69"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "306d0ee4b6204225bb3a39ee6cf64a9c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac0542cd72e14257815fbdd3a34a34f8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4fbfb38d38054e27aef2bdfa420d97ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "988fc6bfe95f44ad917e43fc43ad1ac4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12bdadf4eb284600988fb7bf2fc7c31f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c4019661924493e89d371e16f2c75be"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8dbb86c3e9fc45028fb1dd2c5f07249a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0dc5d0eb68af41b4a67a41a0e7df229c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fade585cd581437eaf8a1a2b24befcfe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e0955593ea0436a84e9213c6ec1747b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4fa1ca009af643dba0365f3e69cbc0a6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5d13a79b02445068d8c29a762b9ea6f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "509daef75aa3742c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
