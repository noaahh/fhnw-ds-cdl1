{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "np.random.seed(1337)\n",
    "load_dotenv()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data partitioning\n",
    "\n",
    "The data is partitioned into 5 folds for cross-validation. Each fold contains a training and validation set. The partitioning is done by segmenting the data by session ID (default). This ensures that all segments from the same session are in the same fold. This is one way to prevent data leakage between the training and validation sets as the movement of a person in a session is likely to be similar across segments. There are other factors that could lead to data leakage, such as the person making the same movement across different sessions. However, based on the dataset available, we can only do so much to prevent data leakage as we have too little data to work with.\n",
    "\n",
    "This notebook will analyse the partitioning made by the `data_pipeline.py` script. It will load the data from the partitions and check for overlapping session IDs between the training and validation sets. It will also look at the distribution of the classes in each fold to ensure that the data is partitioned correctly."
   ],
   "id": "f769166ff7d86a7b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Load data from Parquet\n",
    "\n",
    "The prerequisite to this notebook is to have the data partitioned into Parquet files. The `data_pipeline.py` script should have been run to partition the data. The script partitions the data into 5 folds and saves them to the `data/partitions` directory. You can run the script with the following command:\n",
    "\n",
    "```bash\n",
    "python src/data_pipeline.py partitioning.k_folds=5\n",
    "```"
   ],
   "id": "e8f58b696d295f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "PARTITIONS_PATH = \"../data/partitions\"\n",
    "\n",
    "from src.utils import get_partition_paths, get_partitioned_data\n",
    "\n",
    "partitions_paths = get_partition_paths(PARTITIONS_PATH, k_folds=5)\n",
    "data = get_partitioned_data(partitions_paths)\n",
    "print(data.keys())"
   ],
   "id": "a54fe10a60f468c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The data is loaded successfully. The keys in the data dictionary are the following:\n",
    "- `folds`: Contains the training and validation sets for each fold.\n",
    "- `train_all`: Contains all training data. In the case of k-fold cross-validation, this is the union of the validation sets from each fold.\n",
    "- `test`: Contains the test data. Serves as a holdout set to evaluate the model after training."
   ],
   "id": "e3af45f971619533"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i, fold in enumerate(data[\"folds\"]):\n",
    "    fold_dir, train_data, val_data = fold.values()\n",
    "    print(f\"Fold {i + 1} | Train: {train_data.shape} | Validation: {val_data.shape} | {fold_dir}\")\n",
    "    \n",
    "print(f\"Train all shape: {data['train_all'].shape}\")\n",
    "print(f\"Test shape: {data['test'].shape}\")"
   ],
   "id": "e1777212060b27cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Looking at the shapes of the training and validation sets for each fold, we can see that the training set has more data than the validation set. As we split by the session ID, the ratios between the training and validation sets are perfect as sessions can have varying numbers of segments / lengths.",
   "id": "58018f1b7b50612a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ratios = []\n",
    "for i, fold in enumerate(data[\"folds\"]):\n",
    "    _, train_data, val_data = fold.values()\n",
    "    total = train_data.shape[0] + val_data.shape[0]\n",
    "    ratio = (train_data.shape[0] / total, val_data.shape[0] / total)\n",
    "    ratios.append(ratio)\n",
    "    \n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "barWidth = 0.3\n",
    "r1 = np.arange(len(ratios))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "\n",
    "plt.bar(r1, [r[0] for r in ratios], color='b', width=barWidth, edgecolor='grey', label='Train')\n",
    "plt.bar(r2, [r[1] for r in ratios], color='r', width=barWidth, edgecolor='grey', label='Validation')\n",
    "\n",
    "for i, r in enumerate(ratios):\n",
    "    plt.text(i, r[0] / 2, f'{r[0]*100:.2f}%', ha='center', va='center', color='white')\n",
    "    plt.text(i + barWidth, r[1] / 2, f'{r[1]*100:.2f}%', ha='center', va='center', color='white')\n",
    "\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('Train vs Validation ratio for each fold')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "123fe838029bdc4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The plot shows the percentage ratio of the training and validation sets for each fold. The ratios are close to 80% training and 20% validation for each fold but as we split by session ID, the ratios can vary slightly.",
   "id": "3280fb48d4596641"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data distribution by class for each partition\n",
    "\n",
    "After looking at the partitioning, we can check the distribution of the classes in each fold. This is to ensure that the data is partitioned correctly and that the classes are distributed evenly across the training and validation sets. Stratification is part of the default partitioning process, so the classes should be distributed approximately the same across the training and validation sets."
   ],
   "id": "d5519a6fff86dea1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_fold_label_distribution(y_train, y_val, title):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    sns.countplot(x='label', data=y_train, ax=ax[0])\n",
    "    ax[0].set_title('Train')\n",
    "    total_train = y_train.shape[0]\n",
    "    for p in ax[0].patches:\n",
    "        percentage = '{:.1f}%'.format(100 * p.get_height() / total_train)\n",
    "        x = p.get_x() + p.get_width() / 2\n",
    "        y = p.get_height()\n",
    "        ax[0].annotate(percentage, (x, y), ha='center', va='bottom')\n",
    "    \n",
    "    sns.countplot(x='label', data=y_val, ax=ax[1], order=y_train['label'])\n",
    "    ax[1].set_title('Validation')\n",
    "    total_val = y_val.shape[0]\n",
    "    for p in ax[1].patches:\n",
    "        percentage = '{:.1f}%'.format(100 * p.get_height() / total_val)\n",
    "        x = p.get_x() + p.get_width() / 2\n",
    "        y = p.get_height()\n",
    "        ax[1].annotate(percentage, (x, y), ha='center', va='bottom')\n",
    "    \n",
    "    fig.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "for i, fold in enumerate(data[\"folds\"]):\n",
    "    _, train_data, val_data = fold.values()\n",
    "    plot_fold_label_distribution(train_data, val_data, f'Class distribution for fold {i + 1}')"
   ],
   "id": "f9dea8e5c4db84e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The class distribution for each fold is plotted above. The classes are distributed approximately the same across the training and validation sets but there are some variations.\n",
    "\n",
    "For example in fold 5 there is quite a big difference in the distribution of the classes between the training and validation sets. This is mainly because there is simply not enough data to have a perfect distribution. One option to mitigate the issue even more at the trade-off of having less data for training is to use a maximum session length truncation. Per default the sessions are truncated to a total maximum length of 180 seconds. This can be changed by setting the `preprocessing.max_session_length_s` parameter in the `configs/preprocessing/default.yaml` file. This will ensure that the sessions are more balanced in terms of the class distribution but the model will have less data to train on."
   ],
   "id": "8929c9b870915304"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Overlapping session IDs between training and validation sets\n",
    "\n",
    "We will check for overlapping session IDs between the training and validation sets. This is to ensure that the partitioning is done correctly and that there is no data leakage between the training and validation sets."
   ],
   "id": "d4678b3e476b1c9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def check_overlapping_session_ids(train_data, val_data):\n",
    "    train_session_ids = set(train_data['session_id'])\n",
    "    val_session_ids = set(val_data['session_id'])\n",
    "    overlapping_session_ids = train_session_ids.intersection(val_session_ids)\n",
    "    return overlapping_session_ids\n",
    "\n",
    "for i, fold in enumerate(data[\"folds\"]):\n",
    "    _, train_data, val_data = fold.values()\n",
    "    overlapping_session_ids = check_overlapping_session_ids(train_data, val_data)\n",
    "    assert len(overlapping_session_ids) == 0, \"Overlapping session IDs found\"\n",
    "    \n",
    "print(\"No overlapping session IDs found\")"
   ],
   "id": "b44d3dd445dc5a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The check for overlapping session IDs passed. This means that the partitioning is done correctly and there is no data leakage between the training and validation sets.",
   "id": "a5ee90476f82f6ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Looking at a random segment\n",
    "\n",
    "Further analysis can be done by looking at a random segment from the training set. This will give us an idea of what the data looks like and how the features are distributed.\n",
    "\n",
    "Let's plot the accelerometer data for a random segment from the training set."
   ],
   "id": "ac5ff563c71b101b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fold = np.random.choice(data[\"folds\"])\n",
    "_, train_data, val_data = fold.values()\n",
    "\n",
    "segment_id = train_data['segment_id'].sample(1, random_state=42).values[0]\n",
    "segment = train_data[train_data['segment_id'] == segment_id]\n",
    "segment = segment.sort_values(by='_time')"
   ],
   "id": "d9be95f677ff8ece",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After sampling and sorting the segment data by time, we can print out some information about the segment.",
   "id": "8b9bc3d5f9bcb385"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Segment ID: {segment_id}\")\n",
    "print(f\"Start time: {segment['_time'].min()}\")\n",
    "print(f\"End time: {segment['_time'].max()}\")\n",
    "print(f\"Segment duration: {segment['_time'].max().timestamp() - segment['_time'].min().timestamp()} seconds\")\n",
    "print(f\"Label: {segment['label'].values[0]}\")"
   ],
   "id": "7ecbc77bcd2d3238",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The segment contains accelerometer data for 5 seconds. Let's plot the accelerometer data for this segment.",
   "id": "5d8d31afdd5e87dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(segment['_time'], segment['accelerometer_x'])\n",
    "plt.plot(segment['_time'], segment['accelerometer_y'])\n",
    "plt.plot(segment['_time'], segment['accelerometer_z'])\n",
    "plt.title('Accelerometer XYZ data for a random segment (label: {})'.format(segment['label'].values[0]))\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Acceleration')\n",
    "plt.legend(['X', 'Y', 'Z'])\n",
    "plt.show()"
   ],
   "id": "f3f0de839b20aec3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The plot shows the accelerometer data for the segment. The data is noisy and the acceleration values are centered around 0. The data will be preprocessed and fed into the model for training.\n",
    "\n",
    "This concludes the analysis of the data partitioning. The partitioning is done correctly and there is no data leakage between the training and validation sets. The classes are distributed approximately the same across the training and validation sets. The data is ready for training the model."
   ],
   "id": "c27a92f82ef8168e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
