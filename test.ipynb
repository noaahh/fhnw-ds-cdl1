{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-09T23:24:15.256228Z",
     "start_time": "2024-05-09T23:24:13.951304Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import lightning as pl\n",
    "from torchmetrics import Accuracy, F1Score\n",
    "\n",
    "from src.data.dataset import SensorDataModule\n",
    "from src.data.partition_helper import get_partitioned_data, get_partition_paths\n",
    "\n",
    "dataset = SensorDataModule(get_partition_paths(\"./data/splits\", k_folds=5), batch_size=32)\n",
    "\n",
    "dataset.setup()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T23:24:15.265405Z",
     "start_time": "2024-05-09T23:24:15.257619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import Accuracy, F1Score\n",
    "\n",
    "class BidirectionalLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=True, dropout=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        return x\n",
    "\n",
    "class ForwardLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        return x\n",
    "\n",
    "class CustomBidirectionalLayer(nn.Module):\n",
    "    def __init__(self, forward_layer, input_dim, hidden_dim, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.forward_layer = forward_layer\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        \n",
    "    def init_weights_from_forward_layer(self):\n",
    "        # Fetch the parameters of the forward LSTM layer from ForwardLayer\n",
    "        forward_params = list(self.forward_layer.lstm.parameters())\n",
    "        # Fetch the parameters of the forward part of the bidirectional LSTM\n",
    "        bidirectional_params = list(self.lstm.parameters())\n",
    "\n",
    "        # Half the parameters belong to the forward LSTM part of the bidirectional LSTM (assuming the forward and backward have the same number of parameters)\n",
    "        for i in range(len(forward_params)):\n",
    "            if i < len(bidirectional_params) // 2:\n",
    "                bidirectional_params[i].data.copy_(forward_params[i].data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ensure the forward weights are updated each time forward is called\n",
    "        self.init_weights_from_forward_layer()\n",
    "        x, _ = self.lstm(x)\n",
    "        return x\n",
    "\n",
    "class ResidualLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout, num_blocks):\n",
    "        super().__init__()\n",
    "        self.bidirectional_layers = nn.ModuleList([\n",
    "            BidirectionalLayer(input_dim if i == 0 else hidden_dim * 2, hidden_dim, num_layers, dropout)\n",
    "            for i in range(num_blocks)\n",
    "        ])\n",
    "\n",
    "        output_dim_from_lstm = hidden_dim * 2\n",
    "\n",
    "        self.fc_layers = nn.ModuleList([\n",
    "            nn.Linear(input_dim if i == 0 else output_dim_from_lstm, output_dim_from_lstm)\n",
    "            for i in range(num_blocks + 2)\n",
    "        ])\n",
    "\n",
    "        self.batch_norm = nn.BatchNorm1d(output_dim_from_lstm)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.bidirectional_layers[0](x)\n",
    "        residual = F.relu(self.fc_layers[1](x))\n",
    "\n",
    "        x = self.bidirectional_layers[1](residual)\n",
    "        x = F.relu(self.fc_layers[2](x)) + residual  \n",
    "\n",
    "        x = x.transpose(1, 2)  \n",
    "        x = self.batch_norm(x)\n",
    "        x = x.transpose(1, 2)  \n",
    "\n",
    "        x = F.relu(self.fc_layers[3](x))  \n",
    "\n",
    "        return x\n",
    "\n",
    "class DeepBidirectionalLSTMs(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout, num_blocks, output_dim):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lstm_networks = nn.ModuleList([ResidualLayer(hidden_dim if i == 0 else hidden_dim * 2, hidden_dim, num_layers, dropout, num_blocks) for i in range(num_blocks)])\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.accuracy = Accuracy(task='multiclass', num_classes=output_dim)\n",
    "        self.f1_score = F1Score(num_classes=output_dim, average='weighted', task='multiclass')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x initially has shape [batch_size, seq_length, input_dim], e.g., [32, 251, 64]\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        # Flatten the batch and sequence length dimensions to apply the FC layer to each timestep individually\n",
    "        x = x.view(-1, x.size(2))  # Reshape to [batch_size * seq_length, input_dim], e.g., [32*251, 64]\n",
    "        x = F.relu(self.fc1(x))    # Transform each timestep through the FC layer, output shape [32*251, hidden_dim]\n",
    "\n",
    "        # Restore the original sequence format\n",
    "        x = x.view(batch_size, seq_len, -1)  # Reshape back to [batch_size, seq_length, hidden_dim]\n",
    "\n",
    "        # Process each sequence through the LSTM layers\n",
    "        for lstm in self.lstm_networks:\n",
    "            x = lstm(x)\n",
    "\n",
    "        # Take the last timestep's output for classification\n",
    "        x = x[:, -1, :]  # Output of the last timestep, shape [batch_size, hidden_dim]\n",
    "        x = self.fc2(x)  # Final classification layer, output shape [batch_size, output_dim]\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y.float())\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        self.log('train_acc', self.accuracy(logits, y))\n",
    "        self.log('train_f1', self.f1_score(logits, y), prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y.float())\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', self.accuracy(logits, y), prog_bar=True)\n",
    "        self.log('val_f1', self.f1_score(logits, y), prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "\n"
   ],
   "id": "65d54d779385e3e3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T23:26:25.210683Z",
     "start_time": "2024-05-09T23:24:15.266110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "for key, fold in dataset.data_dict.items():\n",
    "    train_dataloader, val_dataloader = fold['train'], fold['validate']\n",
    "    trainer = pl.Trainer(max_epochs=5, devices=1, accelerator='mps', log_every_n_steps=10)\n",
    "    model = DeepBidirectionalLSTMs(input_dim=48, hidden_dim=64, output_dim=dataset.num_classes, num_layers=1, dropout=0.2, num_blocks=2)\n",
    "    trainer.fit(model, train_dataloader, val_dataloader)\n",
    "    break\n"
   ],
   "id": "20a6faf6f644c413",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/dmnk/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "/Users/dmnk/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | lstm_networks | ModuleList         | 488 K \n",
      "1 | fc1           | Linear             | 3.1 K \n",
      "2 | fc2           | Linear             | 645   \n",
      "3 | accuracy      | MulticlassAccuracy | 0     \n",
      "4 | f1_score      | MulticlassF1Score  | 0     \n",
      "-----------------------------------------------------\n",
      "492 K     Trainable params\n",
      "0         Non-trainable params\n",
      "492 K     Total params\n",
      "1.971     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "211cebcf29a342d5aba00f81c3f5b982"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a991f9905aec4a15a012a66d04b60a89"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45791c7df7bb4c81ad1a8426cc13081c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67024ef754664cc8a3253e4066120f9e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f2580aa4a064b05a07f63fdc513324a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad1187e323e74354afd873b5b4175da7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12fb5817d61a4c36a591e3a33fd4420d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "/Users/dmnk/PycharmProjects/cdl1-sensor-based/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T20:05:09.289321Z",
     "start_time": "2024-05-09T20:04:55.232629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assuming `train_dataloader` is already defined and available\n",
    "# Fetch the first batch\n",
    "first_batch = next(iter(dataset.data_dict[0]['validate']))\n",
    "\n",
    "# Unpack the first batch\n",
    "data_tensors, labels = first_batch\n",
    "\n",
    "# Print shapes and types to understand the structure\n",
    "print(\"Data tensors shape:\", data_tensors.shape)\n",
    "print(\"Data tensors type:\", type(data_tensors))\n",
    "print(\"Labels shape:\", labels.shape)\n",
    "print(\"Labels type:\", type(labels))\n",
    "\n",
    "# If your tensors are dictionaries (which might be causing the error), print the keys\n",
    "if isinstance(data_tensors, dict):\n",
    "    print(\"Data tensor keys:\", data_tensors.keys())\n",
    "\n",
    "# Optionally, you can visualize or print part of the tensors to understand the actual data\n",
    "print(\"First few data points:\", data_tensors[:5])  # Adjust slicing based on your data size\n",
    "print(\"First few labels:\", labels[:5])\n"
   ],
   "id": "56ef00d67ff0e24d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data tensors shape: torch.Size([32, 251, 48])\n",
      "Data tensors type: <class 'torch.Tensor'>\n",
      "Labels shape: torch.Size([32, 5])\n",
      "Labels type: <class 'torch.Tensor'>\n",
      "First few data points: tensor([[[ 1.5077e-02, -8.4308e-01, -1.2617e+00,  ..., -6.7758e-01,\n",
      "          -5.3039e-02,  5.5554e-01],\n",
      "         [ 8.8432e-03, -8.4308e-01, -1.2617e+00,  ..., -6.7881e-01,\n",
      "          -5.3039e-02,  5.5554e-01],\n",
      "         [ 1.1694e-02, -8.4308e-01, -1.2617e+00,  ..., -6.7948e-01,\n",
      "          -5.3039e-02,  5.5554e-01],\n",
      "         ...,\n",
      "         [-9.1835e-02, -8.4308e-01, -1.2617e+00,  ...,  8.5037e-01,\n",
      "          -5.3039e-02,  5.5554e-01],\n",
      "         [ 2.3238e-01, -8.4308e-01, -1.2617e+00,  ...,  8.3910e-01,\n",
      "          -5.3039e-02,  5.5554e-01],\n",
      "         [ 3.1028e-01, -8.4308e-01, -1.2617e+00,  ...,  8.4028e-01,\n",
      "          -5.3039e-02,  5.5554e-01]],\n",
      "\n",
      "        [[-9.4379e-04, -8.4308e-01,  9.5124e-01,  ..., -9.8356e-01,\n",
      "           7.5225e-01,  3.7390e-01],\n",
      "         [-1.0288e-03, -8.4308e-01,  9.5124e-01,  ..., -9.7817e-01,\n",
      "           7.5225e-01,  3.7390e-01],\n",
      "         [-6.8143e-02, -8.4308e-01,  9.5124e-01,  ..., -9.7326e-01,\n",
      "           7.5225e-01,  3.7390e-01],\n",
      "         ...,\n",
      "         [-5.6426e-01, -8.4308e-01,  9.5124e-01,  ...,  2.7044e-01,\n",
      "           7.5225e-01,  3.7390e-01],\n",
      "         [ 6.8519e-02, -8.4308e-01,  9.5124e-01,  ...,  2.7828e-01,\n",
      "           7.5225e-01,  3.7390e-01],\n",
      "         [ 9.5215e-01, -8.4308e-01,  9.5124e-01,  ...,  2.8364e-01,\n",
      "           7.5225e-01,  3.7390e-01]],\n",
      "\n",
      "        [[-5.0087e-02,  1.2144e-01,  3.9548e-02,  ..., -1.3808e-01,\n",
      "          -8.5833e-01, -4.2604e-01],\n",
      "         [-3.1910e-02,  1.2144e-01,  3.9548e-02,  ..., -1.3561e-01,\n",
      "          -8.5833e-01, -4.2604e-01],\n",
      "         [ 1.7862e-01,  1.2144e-01,  3.9548e-02,  ..., -1.3353e-01,\n",
      "          -8.5833e-01, -4.2604e-01],\n",
      "         ...,\n",
      "         [ 1.9443e+00,  1.2144e-01,  3.9548e-02,  ...,  7.2055e-01,\n",
      "          -8.5833e-01, -4.2604e-01],\n",
      "         [ 1.6235e+00,  1.2144e-01,  3.9548e-02,  ...,  7.4795e-01,\n",
      "          -8.5833e-01, -4.2604e-01],\n",
      "         [ 7.8541e-01,  1.2144e-01,  3.9548e-02,  ...,  7.5628e-01,\n",
      "          -8.5833e-01, -4.2604e-01]],\n",
      "\n",
      "        [[ 2.6312e-01,  5.5011e-01, -1.2225e+00,  ..., -1.1876e+00,\n",
      "           7.5225e-01,  5.8111e-02],\n",
      "         [ 1.6048e-01,  5.5011e-01, -1.2225e+00,  ..., -1.1945e+00,\n",
      "           7.5225e-01,  5.8111e-02],\n",
      "         [ 1.1391e-01,  5.5011e-01, -1.2225e+00,  ..., -1.2020e+00,\n",
      "           7.5225e-01,  5.8111e-02],\n",
      "         ...,\n",
      "         [-2.3066e+00,  5.5011e-01, -1.2225e+00,  ..., -9.6393e-01,\n",
      "           7.5225e-01,  5.8111e-02],\n",
      "         [-1.6526e+00,  5.5011e-01, -1.2225e+00,  ..., -8.6222e-01,\n",
      "           7.5225e-01,  5.8111e-02],\n",
      "         [-9.5987e-01,  5.5011e-01, -1.2225e+00,  ..., -6.3421e-01,\n",
      "           7.5225e-01,  5.8111e-02]],\n",
      "\n",
      "        [[-7.7583e-01,  3.3577e-01,  1.2927e+00,  ...,  6.5217e-01,\n",
      "           3.4960e-01,  4.9754e-01],\n",
      "         [-4.0003e-01,  3.3577e-01,  1.2927e+00,  ...,  6.5535e-01,\n",
      "           3.4960e-01,  4.9754e-01],\n",
      "         [-8.9451e-01,  3.3577e-01,  1.2927e+00,  ...,  6.7414e-01,\n",
      "           3.4960e-01,  4.9754e-01],\n",
      "         ...,\n",
      "         [ 1.2383e+00,  3.3577e-01,  1.2927e+00,  ..., -3.9848e-01,\n",
      "           3.4960e-01,  4.9754e-01],\n",
      "         [-3.2034e-01,  3.3577e-01,  1.2927e+00,  ..., -4.1045e-01,\n",
      "           3.4960e-01,  4.9754e-01],\n",
      "         [-2.1441e+00,  3.3577e-01,  1.2927e+00,  ..., -4.3266e-01,\n",
      "           3.4960e-01,  4.9754e-01]]])\n",
      "First few labels: tensor([[1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1]])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "203f933efa1fe2ca"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
