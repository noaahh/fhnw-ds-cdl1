{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import lightning as pl\n",
    "from torchmetrics import Accuracy, F1Score\n",
    "\n",
    "from src.data.dataset import SensorDataModule\n",
    "from src.data.partition_helper import get_partitioned_data, get_partition_paths\n",
    "\n",
    "dataset = SensorDataModule(get_partition_paths(\"./data/splits\", k_folds=5), batch_size=32)\n",
    "\n",
    "dataset.setup()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import Accuracy, F1Score\n",
    "\n",
    "class BidirectionalLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=True, dropout=dropout if num_layers > 1 else 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        return x\n",
    "\n",
    "class ResidualLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout, num_blocks):\n",
    "        super().__init__()\n",
    "        output_dim = hidden_dim * 2\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.batch_norm = nn.BatchNorm1d(output_dim)\n",
    "\n",
    "        for i in range(num_blocks):\n",
    "            self.layers.append(\n",
    "                nn.Sequential(\n",
    "                    BidirectionalLayer(input_dim if i == 0 else output_dim, hidden_dim, num_layers, dropout),\n",
    "                    nn.Linear(output_dim, output_dim),\n",
    "                    nn.ReLU()\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            residual = x if i == 0 else self.layers[i-1][1](x)\n",
    "            x = layer(x) + residual\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.batch_norm(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "class DeepBidirectionalLSTMs(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout, num_blocks, output_dim):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lstm_networks = ResidualLayer(input_dim, hidden_dim, num_layers, dropout, num_blocks)\n",
    "        self.final_fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.accuracy = Accuracy(task='multiclass', num_classes=output_dim)\n",
    "        self.f1_score = F1Score(num_classes=output_dim, average='weighted', task='multiclass')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lstm_networks(x)\n",
    "        x = x[:, -1, :]  # taking last timestep's output\n",
    "        x = self.final_fc(x)\n",
    "        return x\n",
    "\n",
    "    def _shared_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1) \n",
    "        loss = F.cross_entropy(logits, y.float())\n",
    "\n",
    "        y = torch.argmax(y, dim=1)\n",
    "        acc = self.accuracy(preds, y)\n",
    "        f1 = self.f1_score(preds, y) \n",
    "        print(f\"preds: {preds}, y: {y}, acc: {acc}, f1: {f1}\")\n",
    "\n",
    "        return loss, acc, f1\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, acc, f1 = self._shared_step(batch, batch_idx)\n",
    "        self.log_dict({\"train_loss\": loss, \"train_acc\": acc, \"train_f1\": f1}, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, acc, f1 = self._shared_step(batch, batch_idx)\n",
    "        self.log_dict({\"val_loss\": loss, \"val_acc\": acc, \"val_f1\": f1}, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "\n"
   ],
   "id": "65d54d779385e3e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "for key, fold in dataset.data_dict.items():\n",
    "    train_dataloader, val_dataloader = fold['train'], fold['validate']\n",
    "    trainer = pl.Trainer(max_epochs=20, devices=1, accelerator='mps', log_every_n_steps=10)\n",
    "    model = DeepBidirectionalLSTMs(input_dim=48, hidden_dim=24, output_dim=dataset.num_classes, num_layers=3, dropout=0.2, num_blocks=2)\n",
    "    trainer.fit(model, train_dataloader, val_dataloader)\n",
    "    break\n"
   ],
   "id": "20a6faf6f644c413",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Assuming `train_dataloader` is already defined and available\n",
    "# Fetch the first batch\n",
    "first_batch = next(iter(dataset.data_dict[0]['validate']))\n",
    "\n",
    "# Unpack the first batch\n",
    "data_tensors, labels = first_batch\n",
    "\n",
    "# Print shapes and types to understand the structure\n",
    "print(\"Data tensors shape:\", data_tensors.shape)\n",
    "print(\"Data tensors type:\", type(data_tensors))\n",
    "print(\"Labels shape:\", labels.shape)\n",
    "print(\"Labels type:\", type(labels))\n",
    "\n",
    "# If your tensors are dictionaries (which might be causing the error), print the keys\n",
    "if isinstance(data_tensors, dict):\n",
    "    print(\"Data tensor keys:\", data_tensors.keys())\n",
    "\n",
    "# Optionally, you can visualize or print part of the tensors to understand the actual data\n",
    "print(\"First few data points:\", data_tensors[:5])  # Adjust slicing based on your data size\n",
    "print(\"First few labels:\", labels[:5])\n"
   ],
   "id": "56ef00d67ff0e24d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "203f933efa1fe2ca",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
